# ğŸ§  Doubt_Solver_LLM

![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)


`doubt_solver_llm` is a full-stack local AI pipeline that lets you build, train, and run your own lightweight ChatGPT-style assistant that can answer real-time user questions using fine-tuned language models and live search (DuckDuckGo).

You can:
- Fine-tune models like **TinyLlama**, **Phi-2**, or **Zephyr**
- Automatically build datasets from Google/DuckDuckGo
- Train with `prompt + context + answer` format
- Ask questions via **CLI** or a **Gradio Web App**

---

## ğŸš€ Features

âœ… Fine-tunes open-source LLMs (TinyLlama/Zephyr/etc.)  
âœ… Real-time DuckDuckGo search + context feeding  
âœ… Clean prompt engineering: `### Context:` â†’ `### Question:` â†’ `### Answer:`  
âœ… Auto dataset generation using GPT-backed search  
âœ… Modular scripts for scraping, preprocessing, training, inference  
âœ… CLI + Gradio Web UI for asking questions  
âœ… Lightweight and local-first, works on CPU or GPU

---

## ğŸ“ Project Structure

```
doubt_solver_llm/
â”œâ”€â”€ data/                     # QA datasets (scraped + cleaned)
â”‚   â”œâ”€â”€ google_qa_dataset.json
â”‚   â””â”€â”€ questions.json
â”‚
â”œâ”€â”€ models/                  # Fine-tuned model versions (auto-created)
â”‚   â”œâ”€â”€ fine_tuned_model_20250325_053845/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/                 # Core logic scripts
â”‚   â”œâ”€â”€ scrape_google.py          # Uses Google/DuckDuckGo to collect Q&A
â”‚   â”œâ”€â”€ prepare_dataset.py        # Cleans scraped data
â”‚   â”œâ”€â”€ train_model.py            # Simple static fine-tuning (not recommended)
â”‚   â”œâ”€â”€ train_with_versioning.py  # âœ… Recommended fine-tuning script
â”‚   â””â”€â”€ realtime_answer.py        # Real-time search + local model answering
â”‚
â”œâ”€â”€ inference/              # Interfaces
â”‚   â”œâ”€â”€ ask.py              # CLI Q&A tool
â”‚   â””â”€â”€ server.py           # Gradio web app
â”‚
â”œâ”€â”€ run_pipeline.py         # Full auto-pipeline: scrape â†’ clean â†’ train â†’ serve
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md               # This file
```

---

## ğŸ§ª Quickstart

### 1. ğŸ§° Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. ğŸš€ Run Everything

```bash
python run_pipeline.py
```

This will:
1. Scrape 3 questions via DuckDuckGo
2. Clean and prepare the Q&A data
3. Fine-tune the LLM
4. Launch the Gradio web app

### 3. ğŸ” Use Components Manually

```bash
python scripts/scrape_google.py         # Scrape questions
python scripts/prepare_dataset.py       # Clean data
python scripts/train_with_versioning.py # Fine-tune model
python inference/ask.py                 # Ask from terminal
python inference/server.py              # Use Gradio UI
```

---

## ğŸ§  Fine-Tuning Details

### ğŸ“„ Input Format
Your training data should look like:

```json
{
  "prompt": "What is a neural network?",
  "completion": "A neural network is a series of algorithms that mimic the human brain..."
}
```

This gets converted into:
```
### Question:
What is a neural network?

### Answer:
A neural network is...
```

### ğŸ§  Model Used
Default: `TinyLlama/TinyLlama-1.1B-Chat-v1.0`  
You can change this in `train_with_versioning.py`:
```python
MODEL_NAME = "microsoft/phi-2"
```

### ğŸ” Versioned Output
Models are saved like:
```
models/fine_tuned_model_YYYYMMDD_HHMMSS/
```
Each time you run `train_with_versioning.py`

---

## ğŸ¤– Real-Time Web + CLI Search QA

### CLI:
```bash
python scripts/realtime_answer.py
```
You can now ask:
```
Q: Why do cats purr?
```
And it will:
1. Search the web live with DuckDuckGo
2. Extract relevant snippets
3. Generate a local LLM-powered answer from context

### Gradio UI:
```bash
python inference/server.py
```
Access from your browser and type questions.

---

## ğŸ“¦ Dependencies

```txt
transformers
datasets
duckduckgo-search
requests
beautifulsoup4
gradio
openai
```

Install with:
```bash
pip install -r requirements.txt
```

---

## ğŸ” License

MIT License â€” Free to use, modify, and build on.

---

## ğŸ‘¨â€ğŸ’» Author

Created by [Ashrith Chandan](https://github.com/AshrithChandan)  
Contributions welcome! Letâ€™s build smarter local AI together ğŸ’ª
